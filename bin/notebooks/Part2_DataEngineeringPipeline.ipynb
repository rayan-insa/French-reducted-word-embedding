{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Pipeline for the Second Part of the Project : Fine-tuning of the 30-dim embeds\n",
    "\n",
    "\n",
    "In this notebook, we will fine-tune the reduced embeddings. To do so, we will fetch a corpus training data from a few Wikipedia pages of x words. We also create id pairs of context and central words. Once this done, we fetch the x 300-dim corresponding word embeddings from fasttext. We then put them through the previously saved AutoEncoder that returns the bottleneck neurons, which are the reduced embeddings of 30 dimensions. Finally, we save the reduced embeddings and the data corpuses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Required Libraries\n",
    "\n",
    "We will start by loading the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")  # Move up one directory\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import wikipediaapi\n",
    "import spacy\n",
    "from utils.utils import DataSamplization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from models.autoencoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Wikipedia-Extracted French Data\n",
    "\n",
    "We will load the Wikipedia-extracted French data for training the word2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = \"WikipediaAPI/0.5 (Academic Project; rayan.hanader@gmail.com)\"\n",
    "wiki_fr = wikipediaapi.Wikipedia(language='fr', extract_format=wikipediaapi.ExtractFormat.WIKI, user_agent=user_agent)\n",
    "\n",
    "\n",
    "topics = [\n",
    "    \"Animal domestique\", \"Animal de compagnie\"\n",
    "]\n",
    "\n",
    "\n",
    "output_dir = \"data/wikipediaDump\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for topic in topics:\n",
    "    page = wiki_fr.page(topic)\n",
    "    if page.exists():\n",
    "        print(f\"Fetching article: {topic}\")\n",
    "        with open(f\"{output_dir}/{topic.replace(' ', '_')}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(page.text)\n",
    "    else:\n",
    "        print(f\"Article not found: {topic}\")\n",
    "\n",
    "print(f\"Articles fetched and saved in {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing of the extracted data\n",
    "\n",
    "We preprocess the wikipedia data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Animal_de_compagnie.txt\n",
      "Processing Animal_domestique.txt\n",
      "Loading saved FastText model...\n"
     ]
    }
   ],
   "source": [
    "# Load SpaCy's French language model\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Define directories\n",
    "input_dir = \"data/wikipediaDump\"\n",
    "preprocessed_dir = \"data/preprocessedWikiDump\"\n",
    "os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "\n",
    "def preprocess_text_spacy(text):\n",
    "    \"\"\"\n",
    "    Preprocess the input text using spaCy.\n",
    "    - Tokenization\n",
    "    - Lowercasing\n",
    "    - Stopword removal\n",
    "    - Removal of non-alphabetic tokens\n",
    "    \"\"\"\n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text)\n",
    "    # Filter tokens: keep alphabetic tokens, not stopwords, and in lowercase\n",
    "    tokens = [token.text.lower() for token in doc if token.is_alpha and not token.is_stop]\n",
    "    return tokens\n",
    "\n",
    "# Process each article\n",
    "words = []\n",
    "output_path = os.path.join(preprocessed_dir, \"preprocessedWikiDump.txt\")\n",
    "for file_name in os.listdir(input_dir):\n",
    "    input_path = os.path.join(input_dir, file_name)\n",
    "\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        print(f\"Processing {file_name}\")\n",
    "        with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Preprocess the text\n",
    "        tokens = preprocess_text_spacy(text)\n",
    "        words+=tokens\n",
    "\n",
    "\n",
    "\n",
    "dataSamplization = DataSamplization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fetching of the corresponding embeddings from fasttext\n",
    "\n",
    "We fecth the 300-dim embeddings corresponding to the words of the corpus previously fetched from Wikipedia.\n",
    "We pass the embeddings through the encoder to get the corresponding bottleneck embeddings of 30-dim.\n",
    "We also extract the IDs of the words in order to construct the future Skip-gram pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('animal', array([-3.20413075e-02, -8.37033242e-03,  7.30173737e-02, -7.97412023e-02,\n",
      "       -7.69651830e-02, -5.42337494e-03,  5.64670451e-02,  1.16956020e-02,\n",
      "        3.85769606e-02, -3.51716466e-02,  8.05939436e-02,  2.11401861e-02,\n",
      "       -2.21901424e-02, -7.26218969e-02,  3.11316494e-02, -7.59886065e-03,\n",
      "        2.42326912e-02,  7.00246096e-02,  2.48890072e-02, -2.52103899e-02,\n",
      "       -1.01999179e-01,  7.01836944e-02, -8.36341269e-03, -7.77921686e-03,\n",
      "        7.37397596e-02,  3.73775661e-02, -7.65878484e-02, -1.55226355e-02,\n",
      "        1.63189676e-02,  1.38134500e-02,  3.77668813e-02,  6.13541678e-02,\n",
      "       -1.33383647e-02, -7.59667009e-02,  3.31273861e-02,  2.04847157e-02,\n",
      "        4.56130020e-02,  5.28351776e-02, -1.96153522e-02,  7.45140985e-02,\n",
      "       -5.10749705e-02, -9.68552101e-03, -4.37516011e-02,  4.10298221e-02,\n",
      "       -7.65891895e-02,  3.67603004e-02, -7.95678701e-03,  3.80145684e-02,\n",
      "        7.39008859e-02,  2.94812862e-02, -5.93920425e-03, -1.81104522e-02,\n",
      "        5.18741794e-02, -1.08728036e-02,  1.80710107e-02,  7.44693652e-02,\n",
      "       -4.38865460e-02,  4.03666049e-02, -9.71165970e-02,  6.98324814e-02,\n",
      "       -4.93509024e-02,  2.95413192e-02,  5.31660430e-02,  9.01188254e-02,\n",
      "       -1.21009527e-02,  8.94736126e-02,  2.12518144e-02, -2.87255403e-02,\n",
      "        4.70355414e-02, -4.70522791e-04, -3.28250788e-02,  2.51650047e-02,\n",
      "        3.29263546e-02,  6.88437447e-02,  1.85565650e-02, -1.56657770e-02,\n",
      "        6.58972189e-02, -3.37759517e-02, -9.94348228e-02, -1.33527294e-02,\n",
      "        7.62487343e-03, -6.99460730e-02, -1.47967741e-01, -3.86855416e-02,\n",
      "        2.47006826e-02,  1.27786370e-02,  1.06019927e-02,  9.10950005e-02,\n",
      "        6.55831918e-02, -4.77130786e-02,  3.96822253e-03,  2.85470374e-02,\n",
      "       -4.97428514e-02, -4.28752713e-02, -9.54539701e-02, -2.64946576e-02,\n",
      "        3.62743959e-02,  2.96542048e-02, -5.59102073e-02,  1.01323485e-01,\n",
      "       -4.03758250e-02,  1.32915244e-01, -2.47495784e-03, -3.94547451e-03,\n",
      "        5.14392275e-03, -7.75837526e-02, -8.65505263e-02, -4.48439121e-02,\n",
      "       -3.27028260e-02,  1.35980695e-02, -7.24754333e-02,  9.59732458e-02,\n",
      "        1.32091224e-01, -8.33741650e-02, -7.86758885e-02, -2.48203874e-02,\n",
      "       -3.24010216e-02,  4.96587995e-03,  7.03775883e-03, -2.98744272e-02,\n",
      "       -4.07881923e-02,  2.26866617e-03,  8.47138371e-03,  5.74355898e-03,\n",
      "       -6.70827925e-02,  1.45803262e-02,  1.42599633e-02, -1.56079074e-02,\n",
      "       -1.19514707e-02,  3.01111639e-02,  1.15607530e-02,  1.01669133e-01,\n",
      "        3.89070623e-02, -4.98066023e-02,  4.05849218e-02,  4.47869375e-02,\n",
      "       -1.03264585e-01, -1.61609203e-02,  3.99762113e-03,  1.72581188e-02,\n",
      "        1.19594015e-01,  1.30383449e-03,  7.96031952e-03, -8.57876763e-02,\n",
      "       -1.84438599e-03,  8.76139384e-03,  3.41647975e-02, -2.85555124e-02,\n",
      "       -5.29497974e-02,  4.83521086e-04,  8.91617462e-02, -1.53064774e-02,\n",
      "        4.35344838e-02,  2.19896599e-03, -2.22370625e-02,  1.11561120e-01,\n",
      "        5.77276237e-02, -3.50855999e-02, -6.91287741e-02, -2.11392492e-02,\n",
      "        2.35064011e-02, -2.27987841e-02, -3.19440477e-02, -9.40608904e-02,\n",
      "       -4.25868146e-02,  1.41878398e-02,  2.72471998e-02, -9.41276550e-03,\n",
      "       -4.73480001e-02,  2.21522991e-02,  8.44157711e-02, -2.06440929e-02,\n",
      "       -1.14720231e-02, -4.15292606e-02,  5.28901480e-02,  4.46644314e-02,\n",
      "       -2.70021465e-02, -6.65620789e-02, -3.68569084e-02,  3.72648947e-02,\n",
      "       -1.25778175e-03,  5.20427898e-02, -1.05366586e-02,  3.26836552e-03,\n",
      "       -3.66793834e-02,  5.55798551e-03,  5.25338165e-02, -1.73862167e-02,\n",
      "        6.45985827e-02, -9.00400504e-02, -2.31559575e-02,  1.11563196e-02,\n",
      "       -2.84703132e-02, -4.27955054e-02,  6.73202425e-02,  7.08309337e-02,\n",
      "       -8.89886823e-03, -1.44406257e-03,  3.39287184e-02, -2.46125776e-02,\n",
      "        1.76522620e-02,  2.03726273e-02, -9.15050134e-02, -4.81477492e-02,\n",
      "       -1.59180611e-02,  2.96305995e-02,  9.92530510e-02,  2.86842734e-02,\n",
      "        1.35139348e-02,  7.04755113e-02,  2.86868517e-03, -6.16781414e-02,\n",
      "        5.46262972e-02, -7.94970170e-02,  3.37474346e-02,  8.60777274e-02,\n",
      "        2.60738619e-02,  4.96006384e-02,  2.38717552e-02,  7.13406205e-02,\n",
      "       -1.03540026e-01, -3.93663980e-02, -1.42802863e-04,  5.94637357e-02,\n",
      "       -4.88516167e-02, -9.16862609e-06,  1.19670993e-02,  1.27251133e-01,\n",
      "        5.16942404e-02, -5.66176884e-02, -4.25853617e-02, -3.01410239e-02,\n",
      "        6.23659305e-02, -5.48580401e-02,  3.11075803e-02,  5.48031591e-02,\n",
      "       -2.74938196e-02, -3.66648287e-03,  4.95207310e-02,  8.16133060e-03,\n",
      "        6.66630408e-03,  3.35592516e-02, -2.22156476e-02, -6.63308278e-02,\n",
      "       -7.00385794e-02,  4.69950363e-02,  1.89104229e-02,  3.68693331e-03,\n",
      "        3.12967487e-02,  3.17678824e-02, -3.00854445e-02,  2.43944209e-02,\n",
      "        2.42334530e-02,  3.62503938e-02, -8.90094042e-03,  4.28013392e-02,\n",
      "        5.22562265e-02, -5.16373515e-02, -7.44678825e-03, -4.65283580e-02,\n",
      "       -2.98353136e-02, -3.96695621e-02, -1.87465902e-02, -1.04097225e-01,\n",
      "       -7.64043480e-02, -1.02481153e-02,  1.09956503e-01,  6.77444637e-02,\n",
      "       -8.05723015e-03, -1.13506811e-02, -1.58630405e-03, -6.12984486e-02,\n",
      "       -1.99005916e-03,  4.18338552e-02, -2.81844623e-02, -2.89440397e-02,\n",
      "        3.91390733e-02,  3.11791189e-02,  8.56809989e-02,  3.23703699e-02,\n",
      "        6.58671409e-02,  4.65232693e-02, -2.57078949e-02, -1.03530370e-01,\n",
      "        3.97055596e-02,  8.24369416e-02, -7.43958866e-03, -1.98365208e-02,\n",
      "        1.20401578e-02,  4.18393724e-02, -1.17612872e-02, -6.37162477e-02,\n",
      "        1.32939845e-01, -2.10837703e-02, -1.34084923e-02, -1.98309086e-02,\n",
      "        1.00226048e-02, -3.23959403e-02,  2.62656901e-02,  9.15341377e-02],\n",
      "      dtype=float32)), ('compagnie', array([ 2.25205775e-02,  1.35339228e-02, -1.77576393e-02,  1.97259132e-02,\n",
      "        3.38083133e-03,  1.00780241e-02,  2.52653621e-02, -1.13674365e-02,\n",
      "        2.04723664e-02, -1.32334922e-02,  5.40154763e-02, -6.24864176e-03,\n",
      "        9.79834702e-03, -2.07157880e-02, -4.05290583e-03, -4.05137241e-03,\n",
      "        1.37240384e-02,  5.84078021e-02,  5.74120693e-03, -2.40805838e-03,\n",
      "       -8.63670558e-03, -1.75221339e-02,  9.16117430e-03, -2.66472772e-02,\n",
      "        2.17671394e-02,  1.68658048e-03, -4.22664285e-02, -3.34183387e-02,\n",
      "        1.00110285e-02,  8.33973568e-03, -1.69517845e-02,  1.23297777e-02,\n",
      "        7.47748185e-03,  5.49520086e-03,  8.52200203e-03, -1.47629147e-02,\n",
      "        3.68823782e-02,  8.32089595e-03, -9.46986210e-03,  9.04341694e-03,\n",
      "        2.53120791e-02, -4.97946050e-04,  1.63906603e-03,  3.11232209e-02,\n",
      "       -6.02483824e-02,  2.32134461e-02,  1.65486373e-02,  1.73525289e-02,\n",
      "        1.46009782e-02,  1.43496064e-03,  1.49415508e-02,  1.28900409e-02,\n",
      "        2.56612152e-02, -7.11944187e-03,  1.56889725e-02,  4.39693825e-03,\n",
      "        6.90639950e-03,  2.92943791e-03, -5.43424934e-02, -1.04598766e-02,\n",
      "       -2.20002048e-02, -8.33921507e-03, -2.29861867e-02, -2.06043050e-02,\n",
      "        6.25872463e-02,  4.19105291e-02,  6.31904043e-03, -2.83244587e-02,\n",
      "        1.85312498e-02,  1.38017600e-02, -2.00158916e-02,  4.41158451e-02,\n",
      "       -9.57611762e-03,  2.29860730e-02, -2.75335982e-02,  4.18935763e-03,\n",
      "        1.45833716e-02, -1.05325244e-02,  3.65141630e-02, -3.57974358e-02,\n",
      "        2.53888089e-02, -5.23317000e-03, -4.89074141e-02, -4.90585305e-02,\n",
      "        1.71808153e-02, -5.97111844e-02,  4.93114293e-02,  2.70898193e-02,\n",
      "        1.86872333e-02, -3.56895700e-02,  4.48392555e-02,  2.11170893e-02,\n",
      "       -3.08274999e-02, -6.18845643e-03,  3.46367992e-02, -2.55474132e-02,\n",
      "        2.22714338e-02, -6.63604587e-04, -1.01529900e-02,  4.91187163e-02,\n",
      "       -1.21256132e-02,  2.93655545e-02,  4.68853638e-02,  3.27688567e-02,\n",
      "       -3.29034105e-02,  1.14836916e-02, -6.91349804e-03, -3.65462601e-02,\n",
      "        2.38178167e-02,  9.27061215e-02, -4.72440720e-02,  3.25971469e-02,\n",
      "        3.48525308e-03, -3.31122205e-02,  1.40748043e-02, -1.15044545e-02,\n",
      "        2.80914791e-02, -1.60154365e-02,  7.74753280e-04,  1.17389318e-02,\n",
      "        2.05083750e-04, -2.78139561e-02,  1.50560972e-03,  7.70992413e-03,\n",
      "       -3.63795273e-02, -9.12112370e-03,  7.52156600e-04, -1.80654302e-02,\n",
      "       -2.09278911e-02, -2.34250631e-02, -8.17030668e-03,  1.98605247e-02,\n",
      "       -2.69005075e-03, -2.48013455e-02,  4.56547514e-02,  3.18960473e-02,\n",
      "       -2.89543215e-02, -1.70026571e-02,  5.76327890e-02, -2.78320257e-03,\n",
      "        3.16518173e-02, -3.69490124e-02, -2.31900299e-03, -2.30325125e-02,\n",
      "        4.63666441e-03, -1.86737459e-02,  1.46350265e-02,  8.17294605e-03,\n",
      "       -2.39485465e-02,  1.19910575e-03,  5.00315651e-02, -7.10328855e-03,\n",
      "        8.37481394e-03, -8.60540196e-04, -7.11822649e-03, -4.83003855e-02,\n",
      "        1.99048817e-02,  1.53095443e-02, -3.50693008e-03,  2.00604312e-02,\n",
      "        5.40053733e-02,  2.19878405e-02, -2.77367719e-02, -4.34424356e-02,\n",
      "       -1.31406430e-02,  2.08697431e-02, -1.02892611e-03,  1.13462573e-02,\n",
      "        2.73372652e-03,  5.10046817e-03,  3.29312831e-02,  4.46375459e-03,\n",
      "        3.01069152e-02,  5.61138131e-02,  4.13950626e-03,  2.90159583e-02,\n",
      "        1.43534290e-02, -3.45960893e-02,  4.13234234e-02,  1.74926035e-02,\n",
      "       -6.95429370e-03, -7.78252259e-03,  2.13554632e-02, -7.65101090e-02,\n",
      "        2.09597871e-02,  7.71774724e-03,  3.16011086e-02,  5.94307575e-03,\n",
      "        3.61804180e-02, -2.02253871e-02,  2.42576059e-02,  4.32221070e-02,\n",
      "        4.70443815e-03, -3.14703882e-02,  3.50147635e-02, -1.78470332e-02,\n",
      "       -3.91003639e-02,  8.29032995e-03,  8.55075661e-03, -1.40015418e-02,\n",
      "        4.27826867e-03, -7.50419050e-02, -4.49985787e-02, -1.28290653e-02,\n",
      "        9.91311017e-03, -8.13635997e-05,  4.47303876e-02,  4.65490855e-02,\n",
      "        1.15656024e-02, -1.58154580e-03, -7.98708200e-03, -2.51962710e-02,\n",
      "        4.94787395e-02, -2.27066893e-02, -4.72506415e-03,  7.76652321e-02,\n",
      "       -2.45845877e-02,  2.20858362e-02, -1.12696886e-02,  2.29895934e-02,\n",
      "        1.25070363e-02, -5.36594279e-02, -4.16218191e-02,  1.44290235e-02,\n",
      "       -1.80603098e-03,  4.06971574e-03,  3.26685049e-02,  4.66969460e-02,\n",
      "        2.17531677e-02,  1.53837670e-02, -1.02094039e-02, -7.03690052e-02,\n",
      "        2.63575930e-02, -4.93063554e-02,  2.86114998e-02,  2.27490216e-02,\n",
      "       -5.69837205e-02, -1.83677860e-02,  3.74901518e-02, -2.03726590e-02,\n",
      "       -2.30238284e-03,  4.40907944e-03,  2.30968539e-02, -1.09402277e-02,\n",
      "       -2.00262442e-02, -1.40705202e-02, -7.32995849e-03, -1.11074804e-03,\n",
      "       -5.74322091e-03, -9.83747095e-03, -1.64010189e-02, -1.40346698e-02,\n",
      "        2.54244246e-02, -3.20205241e-02, -5.03651053e-02,  1.86527148e-02,\n",
      "        6.50692731e-03, -7.41029158e-03, -2.31167488e-03, -2.24494021e-02,\n",
      "        3.98853980e-03, -4.22213320e-03, -2.23384164e-02, -1.90931167e-02,\n",
      "       -2.79903766e-02,  4.95021641e-02,  3.02437153e-02,  2.49596834e-02,\n",
      "        2.67838929e-02, -9.42089502e-03, -9.89095494e-03,  2.45958678e-02,\n",
      "       -1.59442909e-02, -2.88145454e-03, -4.58724126e-02, -2.88489945e-02,\n",
      "       -1.36799831e-03,  1.03717912e-02, -8.09978973e-03,  1.52882319e-02,\n",
      "       -5.05628660e-02, -3.27647501e-03, -3.56731676e-02, -1.15701193e-02,\n",
      "       -2.15496048e-02,  2.05683708e-02, -1.13140303e-03,  2.56675892e-02,\n",
      "       -2.65201181e-02, -2.88975798e-03,  1.87720861e-02, -2.43884958e-02,\n",
      "        5.71443737e-02,  9.85786039e-03,  3.08212694e-02, -1.26327742e-02,\n",
      "       -2.35123001e-02,  1.48228630e-02,  3.74593362e-02,  2.04136595e-02],\n",
      "      dtype=float32)), ('recevant', array([-2.75937971e-02,  1.29045232e-03,  9.74664651e-03,  2.14405935e-02,\n",
      "       -5.87519854e-02,  8.95277481e-04, -5.78451622e-03, -2.06200108e-02,\n",
      "        4.04875353e-03, -1.50532869e-03, -4.52038785e-03, -5.09614032e-03,\n",
      "       -6.41420484e-05,  4.84893210e-02, -2.06886195e-02, -4.80864421e-02,\n",
      "       -3.21844555e-02,  2.24115215e-02,  8.02603172e-05,  9.00475215e-03,\n",
      "       -8.87065232e-02,  1.54477335e-03,  1.67400180e-03, -4.18585353e-02,\n",
      "        1.25918249e-02, -1.68234147e-02, -1.22082178e-02, -2.19885726e-02,\n",
      "        4.06447519e-03, -4.66723703e-02, -2.61233840e-02,  4.67031412e-02,\n",
      "        1.49973128e-02,  8.16838443e-02,  1.42486095e-02, -1.12172151e-02,\n",
      "        8.45370144e-02, -2.60710362e-02,  7.26113608e-03, -8.32916722e-02,\n",
      "        2.86347941e-02,  6.00960338e-03,  1.30512890e-05,  2.61352770e-02,\n",
      "       -9.02812034e-02,  3.59760341e-03,  3.35609466e-02,  2.09496804e-02,\n",
      "       -2.96103656e-02, -2.62373779e-02, -9.41624027e-03, -5.89756556e-02,\n",
      "       -1.98888667e-02,  1.28148785e-02,  3.32999416e-02, -1.05116498e-02,\n",
      "       -6.70869742e-03,  2.30470207e-02, -2.72200629e-02, -4.38461229e-02,\n",
      "        5.60790813e-03,  9.95518267e-03, -6.35981234e-03, -5.54758348e-02,\n",
      "       -1.26649644e-02,  4.27166037e-02,  2.38601957e-02, -2.21172199e-02,\n",
      "       -2.98397848e-03,  9.84194409e-03, -6.56711229e-04,  2.55076103e-02,\n",
      "        1.37306182e-02, -4.28607576e-02, -4.74549606e-02,  4.15991619e-02,\n",
      "       -1.88292726e-03,  5.96086902e-04,  9.93892178e-03,  9.28960647e-03,\n",
      "       -2.45583579e-02,  1.35581130e-02, -3.63831446e-02, -1.30692959e-01,\n",
      "        3.03853713e-02, -3.60635445e-02, -4.44995379e-03, -1.61469840e-02,\n",
      "       -8.93752184e-03,  1.61817502e-02, -9.34687406e-02,  9.80333611e-03,\n",
      "        3.72334686e-03, -2.81848852e-03, -4.08216147e-03,  8.06758471e-04,\n",
      "        3.03890575e-02,  1.98266027e-03, -3.15989666e-02,  2.18612282e-03,\n",
      "       -1.20151462e-02, -1.10729132e-02, -2.98983771e-02, -2.55185587e-04,\n",
      "        1.92087702e-02, -5.45704365e-02,  7.17818784e-03,  3.56910117e-02,\n",
      "        3.07865138e-03,  6.09425828e-02,  3.89684290e-02,  4.25080769e-02,\n",
      "        2.85529960e-02, -2.49130093e-02, -2.95008235e-02,  1.65582318e-02,\n",
      "        3.11181502e-05, -6.29750341e-02, -1.16482209e-02,  1.30497096e-02,\n",
      "       -2.18800101e-02, -2.81384680e-02,  2.48974599e-02,  1.80514045e-02,\n",
      "        1.09875780e-02, -3.11252214e-02,  5.70295304e-02,  9.63125192e-03,\n",
      "        6.39562123e-03, -2.02702675e-02, -3.07720397e-02,  1.12556489e-02,\n",
      "       -1.56552382e-02, -1.33799482e-02, -3.12160328e-02, -1.49860955e-03,\n",
      "       -2.81096790e-02, -1.85056357e-03, -2.03589723e-03, -2.67116283e-03,\n",
      "       -6.85030688e-03, -4.26159911e-02,  1.62600745e-02, -2.67960746e-02,\n",
      "        4.30041440e-02, -3.33814658e-02, -5.31232962e-03, -2.18940657e-02,\n",
      "       -1.31754335e-02, -4.71211132e-03,  6.64103553e-02, -3.56545448e-02,\n",
      "        4.43934053e-02,  2.26887818e-02,  6.24837630e-05,  7.36096548e-03,\n",
      "       -1.27719389e-02, -1.28350064e-01, -2.88731493e-02, -3.25216800e-02,\n",
      "       -4.25818935e-03, -2.19657226e-03,  5.76064140e-02, -7.05532543e-03,\n",
      "       -4.92763035e-02,  1.37830926e-02, -5.52485057e-04, -8.58746655e-03,\n",
      "       -4.92454693e-03, -4.69070189e-02,  5.91102391e-02, -1.47445658e-02,\n",
      "       -2.61962768e-02,  2.59568375e-02,  2.01069396e-02, -2.14051828e-02,\n",
      "        6.26778081e-02, -5.96345961e-02,  3.42746787e-02, -5.81629202e-02,\n",
      "       -4.06214315e-03,  6.84775263e-02, -1.04929889e-02, -5.04702963e-02,\n",
      "        1.24129308e-02,  2.41866540e-02,  4.98168133e-02, -7.29377195e-03,\n",
      "        2.20827255e-02, -3.17508765e-02, -5.77201992e-02, -5.60449995e-02,\n",
      "        1.01285316e-02,  4.61818762e-02,  2.06170939e-02,  2.74873935e-02,\n",
      "       -4.60272543e-02,  4.69193645e-02,  3.20480093e-02, -2.88739800e-02,\n",
      "        2.59453617e-02, -1.01834029e-01,  4.60014604e-02, -6.16945438e-02,\n",
      "        2.58588400e-02,  2.94872709e-02,  3.12650129e-02,  1.30525846e-02,\n",
      "       -3.66808362e-02,  1.53919100e-03, -2.52271779e-02, -7.89624602e-02,\n",
      "        6.57619536e-02, -1.41874561e-02, -6.76910020e-03,  6.02080673e-02,\n",
      "        6.91197859e-03,  8.89272057e-03, -9.48639121e-03, -3.56559753e-02,\n",
      "       -5.21528013e-02,  1.40562924e-02,  5.37043735e-02,  7.30306143e-03,\n",
      "        4.13107267e-03, -4.44001295e-02, -4.21159230e-02, -5.63585088e-02,\n",
      "       -3.67239527e-02, -3.69018912e-02, -1.51987420e-02, -1.18183214e-02,\n",
      "        2.06919666e-03, -3.88859883e-02, -1.54742682e-02, -6.73114508e-03,\n",
      "       -6.03525788e-02,  4.20381613e-02, -1.14684002e-02, -2.66976468e-02,\n",
      "        2.18509007e-02,  1.68275386e-02, -1.73562337e-02,  1.87257715e-02,\n",
      "       -9.02821273e-02,  2.93325204e-02, -4.39514332e-02,  2.36186106e-02,\n",
      "        2.72152573e-02, -3.19436304e-02,  2.62034144e-02,  2.70685609e-02,\n",
      "       -1.05942152e-02,  4.28189524e-03,  3.61763835e-02,  3.98892760e-02,\n",
      "       -4.79758717e-03,  1.87398505e-03,  2.40289439e-02,  1.27853989e-03,\n",
      "        3.37113403e-02, -6.93721883e-03, -6.21352568e-02,  4.88512442e-02,\n",
      "        3.98200043e-02,  3.21293138e-02,  5.27945533e-02, -6.82730004e-02,\n",
      "       -5.23984106e-03, -1.17697623e-02, -9.71915852e-03,  5.96015854e-03,\n",
      "       -2.91598830e-02, -3.24133923e-03,  2.37953383e-02, -3.44081372e-02,\n",
      "       -3.14596370e-02, -1.65095441e-02, -4.91600297e-02, -2.62876227e-02,\n",
      "       -5.30793183e-02,  3.17073762e-02,  1.58080980e-02, -1.74747650e-02,\n",
      "        3.17253172e-02,  3.75988241e-03,  3.86072882e-02,  2.69032810e-02,\n",
      "        4.14098762e-02,  2.05069743e-02,  6.68711066e-02,  1.34219006e-02,\n",
      "        2.19793748e-02, -4.34745327e-02, -4.69755195e-02,  1.03959208e-03,\n",
      "        5.66640729e-03,  7.09037296e-03,  9.82403569e-03,  2.01867744e-02],\n",
      "      dtype=float32))]\n",
      "Embeddings saved in data/modelsSavedLocally/wikipedia/300dim_embeddings_DictWithWords.npy\n",
      "Preprocessed articles saved in data/preprocessedWikiDump\n",
      "\n",
      "\n",
      "Passing the embeddings through the AutoEncoder... Please wait...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Embeddings reduced by the AutoEncoder\n",
      "Embeddings saved in data/modelsSavedLocally/wikipedia/30dim_embeddings_ArraySimple.npy\n",
      "Embeddings saved in data/modelsSavedLocally/wikipedia/30dim_embeddings_DictWithWords.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fw/pdp1gm7s2snc095m56hvhtpm0000gn/T/ipykernel_38138/2516230937.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  autoEncoder.load_state_dict(torch.load('data/modelsSavedLocally/autoencoder.pth'))\n"
     ]
    }
   ],
   "source": [
    "wordIds = dataSamplization.getWordsIds(words)\n",
    "wordIdsToMatchEmbeds = dataSamplization.getWordsIdsWihtoutRepeat(words)\n",
    "cp = wordIds.copy()\n",
    "for i in range(len(cp)-1, -1, -1):\n",
    "    if cp[i] == -1:\n",
    "        # Remove the unfound word from the corpus\n",
    "        words.pop(i)\n",
    "        wordIds.pop(i)\n",
    "cp = wordIdsToMatchEmbeds.copy()\n",
    "for i in range(len(cp)-1, -1, -1):\n",
    "    if cp[i] == -1:\n",
    "        wordIdsToMatchEmbeds.pop(i)\n",
    "embeddings = dataSamplization.getWordsEmbeddings(words)\n",
    "\n",
    "# Save the embeddings before reducing as a dict {word : embed}\n",
    "wordsToMatchEmbeds = []\n",
    "alreadySeen = []\n",
    "for word in words:\n",
    "    if word not in alreadySeen:\n",
    "        wordsToMatchEmbeds.append(word)\n",
    "        alreadySeen.append(word)\n",
    "os.makedirs('data/modelsSavedLocally/wikipedia', exist_ok=True)\n",
    "embedsPath = 'data/modelsSavedLocally/wikipedia/300dim_embeddings_DictWithWords.npy'\n",
    "embeds300withWords = {word: embeddings[i] for i, word in enumerate(wordsToMatchEmbeds)}\n",
    "print(list(embeds300withWords.items())[:3])\n",
    "np.save(embedsPath, embeds300withWords)\n",
    "print(f\"Embeddings saved in {embedsPath}\")\n",
    "\n",
    "# Save the preprocessed articles in a file\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\" \".join(words))\n",
    "print(f\"Preprocessed articles saved in {preprocessed_dir}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "best_config = {'hidden_dim1':256, 'hidden_dim2':128, 'learning_rate':0.001, 'batch_size':64}\n",
    "embedding_matrix = np.array(embeddings)\n",
    "embedding_matrix_normalized = scaler.fit_transform(embedding_matrix)\n",
    "embedding_tensor = torch.tensor(embedding_matrix_normalized, dtype=torch.float32)\n",
    "embedding_dataloader = DataLoader(embedding_tensor, batch_size=best_config['batch_size'], shuffle=False)\n",
    "\n",
    "autoEncoder = AutoEncoder(input_dim=300, hidden_dim1=best_config['hidden_dim1'], hidden_dim2=best_config['hidden_dim2'], bottleneck_dim=30)\n",
    "autoEncoder.load_state_dict(torch.load('data/modelsSavedLocally/autoencoder.pth'))\n",
    "\n",
    "# Get the bottleneck outputs for the embeddings\n",
    "print(\"\\n\\nPassing the embeddings through the AutoEncoder... Please wait...\\n\\n\")\n",
    "bottleneck_outputs = []\n",
    "autoEncoder.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in embedding_dataloader:\n",
    "        outputs = autoEncoder.encoder(batch)\n",
    "        bottleneck_outputs.append(outputs)\n",
    "bottleneck_outputs = torch.cat(bottleneck_outputs)\n",
    "print(\"\\n\\nEmbeddings reduced by the AutoEncoder\")\n",
    "\n",
    "\n",
    "# Save the bottleneck outputs\n",
    "bottleneck_outputs = bottleneck_outputs.detach().numpy()\n",
    "embeds_with_id = {wordIdsToMatchEmbeds[i]: bottleneck_outputs[i] for i in range(len(wordIdsToMatchEmbeds))}\n",
    "embedsDictWithWords = {wordsToMatchEmbeds[i] : bottleneck_outputs[i] for i in range(len(wordsToMatchEmbeds))}\n",
    "cp2 = embeds_with_id.copy()\n",
    "cp = wordIds.copy()\n",
    "for idx, (key, embed)  in enumerate(cp2.items()):\n",
    "    for wordIdsIdx, wordId in enumerate(cp):\n",
    "        if key == wordId:\n",
    "            wordIds[wordIdsIdx] = idx\n",
    "embedsPath = 'data/modelsSavedLocally/wikipedia/30dim_embeddings_ArraySimple.npy'\n",
    "finalEmbeds = np.array(list(embeds_with_id.values()))\n",
    "np.save(embedsPath, finalEmbeds)\n",
    "print(f\"Embeddings saved in {embedsPath}\")\n",
    "embedsPath = 'data/modelsSavedLocally/wikipedia/30dim_embeddings_DictWithWords.npy'\n",
    "np.save(embedsPath, embedsDictWithWords)\n",
    "print(f\"Embeddings saved in {embedsPath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Skip-gram (input, output) word ID pairs construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word pairs saved\n"
     ]
    }
   ],
   "source": [
    "# Skip-gram (input, output) word ID pairs construction for a window size of 2\n",
    "\n",
    "\n",
    "word_pairs = []\n",
    "for i in range(1, len(wordIds)):\n",
    "    input_id = wordIds[i]\n",
    "    context = []\n",
    "\n",
    "    if i + 2 < len(wordIds):\n",
    "        context.append(wordIds[i + 1])\n",
    "        context.append(wordIds[i + 2])\n",
    "    else :\n",
    "        if i + 1 < len(wordIds):\n",
    "            context.append(wordIds[i + 1])\n",
    "\n",
    "    if i - 2 >= 0:\n",
    "        context.append(wordIds[i - 2])\n",
    "        context.append(wordIds[i - 1])\n",
    "    else :\n",
    "        if i - 1 >= 0:\n",
    "            context.append(wordIds[i - 1])\n",
    "    \n",
    "    for output_id in context:\n",
    "        word_pairs.append((input_id, output_id))\n",
    "\n",
    "# Save the word ID pairs into a txt file\n",
    "wordPairsPath = 'data/skipgramPairs/word_pairs_fromWikiDump.txt'\n",
    "os.makedirs('data/skipgramPairs', exist_ok=True)\n",
    "with open(wordPairsPath, \"w\") as f:\n",
    "    for pair in word_pairs:\n",
    "        f.write(f\"{pair[0]} {pair[1]}\\n\")\n",
    "print(\"Word pairs saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Similarity test dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsToTestSimilarity = [\n",
    "    (\"chien\", \"chat\"), (\"chien\", \"loup\"),\n",
    "    (\"perruche\", \"perroquet\"), (\"domestication\", \"apprivoisement\"),\n",
    "    (\"élevage\", \"captivité\"), (\"animal\", \"compagnon\"),\n",
    "    (\"animal\", \"chien\"), (\"animal\", \"chat\"),\n",
    "    (\"Animal\", \"Compagnie\"),\n",
    "    (\"Animal\", \"Espèce\"),\n",
    "    (\"Compagnie\", \"Présence\"),\n",
    "    (\"Espèce\", \"Animaux\"),\n",
    "    (\"Animaux\", \"Familiers\"),\n",
    "    (\"Chien\", \"Chat\"),\n",
    "    (\"Maison\", \"Jardin\"),\n",
    "    (\"Objet\", \"Domestication\"),\n",
    "    (\"Présence\", \"Rassurante\"),\n",
    "    (\"Beaux\", \"Talents\")\n",
    "    ]\n",
    "\n",
    "os.makedirs('data/comparaisonDataSet', exist_ok=True)\n",
    "np.save(file=\"data/comparaisonDataSet/wordsToTestSimilarity.npy\", arr=wordsToTestSimilarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "In this notebook, we finished the whole data pipeline for our project. All that is left to do now, is training and applying the Word2Vec model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
